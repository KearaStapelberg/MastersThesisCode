{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pprint, time\n",
    "\n",
    "import nltk\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "from nltk.corpus import treebank\n",
    "from nltk.corpus import brown\n",
    "\n",
    "from nltk.classify import MaxentClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import pycrfsuite\n",
    "from nltk.tag import hmm\n",
    "from nltk.classify import megam\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.tag import BrillTaggerTrainer\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.tag import DefaultTagger\n",
    "from nltk.metrics import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\21947074\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sentences(category, num_words=5000):\n",
    "    # Get all the tagged sentences for the specified category\n",
    "    tagged_sents = list(brown.tagged_sents(categories=category))\n",
    "\n",
    "    # Randomly shuffle the sentences to ensure randomness\n",
    "    random.shuffle(tagged_sents)\n",
    "\n",
    "    # Initialize variables to keep track of the selected sentences and word count\n",
    "    selected_sents = []\n",
    "    word_count = 0\n",
    "\n",
    "    # Iterate through sentences and add them to the selected set until reaching the desired word count\n",
    "    for sent in tagged_sents:\n",
    "        if word_count + len(sent) <= num_words:\n",
    "            selected_sents.append(sent)\n",
    "            word_count += len(sent)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return selected_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_to_evaluate = ['news', 'reviews', 'religion', 'government', 'learned', 'fiction', 'humor', 'romance'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_domain_f1_unigram(categories):\n",
    "    num_categories = len(categories)\n",
    "    f1_matrix = np.zeros((num_categories, num_categories))\n",
    "\n",
    "    for i, train_category in enumerate(categories):\n",
    "        # Get the tagged sentences for the training category\n",
    "        train_tagged_sents = sample_sentences(train_category, num_words=5000)\n",
    "\n",
    "        # Train a tagger on the training category\n",
    "        default_tagger = DefaultTagger('NN')\n",
    "        unigram_tagger = UnigramTagger(train_tagged_sents, backoff=default_tagger)\n",
    "\n",
    "        for j, test_category in enumerate(categories):\n",
    "            if test_category != train_category:\n",
    "                # Get the tagged sentences for the testing category\n",
    "\n",
    "                test_tagged_sents = sample_sentences(test_category, num_words=5000)\n",
    "                test_untagged_words = [tup[0] for sent in test_tagged_sents for tup in sent]\n",
    "\n",
    "                # Evaluate the tagger on the testing category\n",
    "                tagged_sents = unigram_tagger.tag(test_untagged_words)\n",
    "                predicted_tags = [tag for  _,tag in tagged_sents]\n",
    "\n",
    "                # Flatten the actual and predicted tags\n",
    "                actual_tags = [tup[1] for sent in test_tagged_sents for tup in sent]\n",
    "\n",
    "                # Compute the F1 score and store it in the matrix\n",
    "                f1 = f1_score(actual_tags, predicted_tags, average='weighted')\n",
    "                f1_matrix[i, j] = f1\n",
    "\n",
    "    return f1_matrix\n",
    "\n",
    " # Add more categories if needed\n",
    "\n",
    "\n",
    "# random.seed(1234)\n",
    "# f1_matrix_unigram = cross_domain_f1_unigram(categories_to_evaluate)\n",
    "# np.savetxt(\"insert file path here\", f1_matrix_unigram, delimiter=',', fmt='%f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_domain_brill(categories):\n",
    "    num_categories = len(categories)\n",
    "    f1_matrix = np.zeros((num_categories, num_categories))\n",
    "\n",
    "    for i, train_category in enumerate(categories):\n",
    "        # Get the tagged sentences for the training category\n",
    "        train_tagged_sents = sample_sentences(train_category, num_words=5000)\n",
    "\n",
    "        # Train a tagger on the training category\n",
    "        #default_tagger = DefaultTagger('NN')\n",
    "        #unigram_tagger = UnigramTagger(train_tagged_sents, backoff=default_tagger)\n",
    "\n",
    "\n",
    "        default_tagger = DefaultTagger('NN')\n",
    "        unigram_tagger = UnigramTagger(train_tagged_sents, backoff=default_tagger)\n",
    "\n",
    "        templates = nltk.brill.nltkdemo18()\n",
    "        trainer = BrillTaggerTrainer(templates=templates, initial_tagger=unigram_tagger)\n",
    "\n",
    "        # Train the Brill Tagger using the templates\n",
    "        brill_tagger = trainer.train(train_tagged_sents, max_rules=200)\n",
    "\n",
    "        for j, test_category in enumerate(categories):\n",
    "            if test_category != train_category:\n",
    "\n",
    "                # Get the tagged sentences for the testing category\n",
    "                test_tagged_sents = sample_sentences(test_category, num_words=5000)\n",
    "\n",
    "                # Flatten into tagged words\n",
    "                test_untagged_words = [tup[0] for sent in test_tagged_sents for tup in sent]\n",
    "\n",
    "\n",
    "                # get predictions\n",
    "                tagged_sents = brill_tagger.tag(test_untagged_words)\n",
    "\n",
    "                # Flatten the actual and predicted tags\n",
    "                actual_tags = [tup[1] for sent in test_tagged_sents for tup in sent]\n",
    "                predicted_tags = [tag for  _,tag in tagged_sents]\n",
    "\n",
    "                # Compute the F1 score and store it in the matrix\n",
    "                f1 = f1_score(actual_tags, predicted_tags, average='weighted')\n",
    "                f1_matrix[i, j] = f1\n",
    "\n",
    "    return f1_matrix\n",
    "\n",
    "# random.seed(1234)\n",
    "# f1_matrix_brill = cross_domain_brill(categories_to_evaluate)\n",
    "# np.savetxt(\"insert file path here\", f1_matrix_brill, delimiter=',', fmt='%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_domain_f1_hmm(categories):\n",
    "    num_categories = len(categories)\n",
    "    f1_matrix = np.zeros((num_categories, num_categories))\n",
    "\n",
    "    for i, train_category in enumerate(categories):\n",
    "        # Get the tagged sentences for the training category\n",
    "        train_tagged_sents = sample_sentences(train_category, num_words=5000)\n",
    "\n",
    "        # Train a tagger on the training category\n",
    "        hmm_tagger = nltk.HiddenMarkovModelTagger.train(train_tagged_sents)\n",
    "        \n",
    "\n",
    "        for j, test_category in enumerate(categories):\n",
    "            if test_category != train_category:\n",
    "                # Get the tagged sentences for the testing category\n",
    "\n",
    "                test_tagged_sents = sample_sentences(test_category, num_words=5000)\n",
    " \n",
    "                predicted_tags = []\n",
    "                actual_tags = []\n",
    "\n",
    "                for h,sent in enumerate(test_tagged_sents):\n",
    "                    predicted_tags += [tag for _, tag in hmm_tagger.tag([word for word, _ in sent])]\n",
    "                    actual_tags += [tag for _, tag in sent]\n",
    "\n",
    "                # Compute the F1 score and store it in the matrix\n",
    "                f1 = f1_score(actual_tags, predicted_tags, average='weighted')\n",
    "                f1_matrix[i, j] = f1\n",
    "\n",
    "    return f1_matrix\n",
    "\n",
    "\n",
    "# random.seed(1234)\n",
    "# f1_matrix_hmm = cross_domain_f1_hmm(categories_to_evaluate)\n",
    "# np.savetxt(\"insert file path here\", f1_matrix_hmm, delimiter=',', fmt='%f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_features(sentence, i):\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Extract features for a given index in a sentence.\n",
    "\n",
    "    Parameters:\n",
    "    - sentence: List of feature-label pairs.\n",
    "    - i: index\n",
    "\n",
    "    Returns:\n",
    "    - features: a dictionary of features on a given index.\n",
    "    \"\"\"\n",
    "    \n",
    "    word = sentence[i][0]\n",
    "    tag = sentence[i][1]\n",
    "    features = {\n",
    "        'word': word,\n",
    "        'is_first': i == 0,  # if the word is the first word\n",
    "        'is_last': i == len(sentence) - 1,  # if the word is the last word\n",
    "        'is_capitalized': word[0].upper() == word[0],\n",
    "        'is_all_caps': word.upper() == word,  # word is in uppercase\n",
    "        'is_all_lower': word.lower() == word,  # word is in lowercase\n",
    "        # prefix of the word\n",
    "        'prefix-1': word[0],\n",
    "        'prefix-2': word[:2],\n",
    "        'prefix-3': word[:3],\n",
    "        # suffix of the word\n",
    "        'suffix-1': word[-1],\n",
    "        'suffix-2': word[-2:],\n",
    "        'suffix-3': word[-3:],\n",
    "        # extracting previous word\n",
    "        'prev_word': '' if i == 0 else sentence[i - 1][0],\n",
    "        # extracting next word\n",
    "        'next_word': '' if i == len(sentence) - 1 else sentence[i + 1][0],\n",
    "        'has_hyphen': '-' in word,  # if word has a hyphen\n",
    "        'is_numeric': word.isdigit(),  # if word is numeric\n",
    "        'capitals_inside': word[1:].lower() != word[1:]\n",
    "    }\n",
    "\n",
    "    # Add previous tag and its previous tag\n",
    "    prev_tag = '' if i == 0 else sentence[i - 1][1]\n",
    "    prev_prev_tag = '' if i < 2 else sentence[i - 2][1]\n",
    "    features['prev_prev_tag'] = f'{prev_prev_tag}_{prev_tag}'\n",
    "\n",
    "    # Add word after the next word\n",
    "    features['next_next_word'] = '' if i > len(sentence) - 3 else sentence[i + 2][0]\n",
    "\n",
    "    # Add word before the previous word\n",
    "    features['prev_prev_word'] = '' if i < 2 else sentence[i - 2][0]\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_domain_f1_memm(categories, maxit):\n",
    "    num_categories = len(categories)\n",
    "    f1_matrix = np.zeros((num_categories, num_categories))\n",
    "\n",
    "    for i, train_category in enumerate(categories):\n",
    "        # Get the tagged sentences for the training category\n",
    "        train_tagged_sents = sample_sentences(train_category, num_words=5000)\n",
    "\n",
    "                # feature extraction    \n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        for sentence in train_tagged_sents:\n",
    "            X_sentence = []\n",
    "            y_sentence = []\n",
    "            for sent in range(len(sentence)):\n",
    "                X_sentence.append(word_features(sentence, sent))\n",
    "                y_sentence.append(sentence[sent][1])\n",
    "            X_train.append(X_sentence)\n",
    "            y_train.append(y_sentence) \n",
    "\n",
    "        MEMM_train = []  # Collect feature-label pairs for MEMM\n",
    "        for sentence_features, sentence_labels in zip(X_train, y_train):\n",
    "            MEMM_train.extend(list(zip(sentence_features, sentence_labels)))\n",
    "\n",
    "        # Train a tagger on the training category\n",
    "        maxent_classifier = MaxentClassifier.train(MEMM_train, algorithm='gis', max_iter=maxit)\n",
    "        \n",
    "\n",
    "        for j, test_category in enumerate(categories):\n",
    "            if test_category != train_category:\n",
    "                # Get the tagged sentences for the testing category\n",
    "\n",
    "                test_tagged_sents = sample_sentences(test_category, num_words=5000)\n",
    "\n",
    "                X_test = []\n",
    "                y_test = []\n",
    "                for sentence in test_tagged_sents:\n",
    "                    X_sentence = []\n",
    "                    y_sentence = []\n",
    "                    for sent in range(len(sentence)):\n",
    "                        X_sentence.append(word_features(sentence, sent))\n",
    "                        y_sentence.append(sentence[sent][1])\n",
    "                    X_test.append(X_sentence)\n",
    "                    y_test.append(y_sentence) \n",
    "\n",
    "                MEMM_test = []  # Collect feature-label pairs for MEMM\n",
    "                for sentence_features, sentence_labels in zip(X_test, y_test):\n",
    "                    MEMM_test.extend(list(zip(sentence_features, sentence_labels)))\n",
    "\n",
    "                \n",
    "                # predictions \n",
    "                predicted_tags = maxent_classifier.classify_many([features for features, _ in MEMM_test])\n",
    "\n",
    "                actual_tags = [pos for _, pos in MEMM_test]\n",
    "\n",
    "                # Compute the F1 score and store it in the matrix\n",
    "                f1 = f1_score(actual_tags, predicted_tags, average='weighted')\n",
    "                f1_matrix[i, j] = f1\n",
    "\n",
    "    return f1_matrix\n",
    "\n",
    "# random.seed(1234)\n",
    "# f1_matrix_memm = cross_domain_f1_memm(categories_to_evaluate, maxit=30)\n",
    "# np.savetxt(\"insert file path here\", f1_matrix_memm, delimiter=',', fmt='%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CRF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_domain_f1_crf(categories, paramgrid):\n",
    "    num_categories = len(categories)\n",
    "    f1_matrix = np.zeros((num_categories, num_categories))\n",
    "\n",
    "    for i, train_category in enumerate(categories):\n",
    "\n",
    "        # Get the tagged sentences for the training category\n",
    "        train_tagged_sents = sample_sentences(train_category, num_words=5000)\n",
    "\n",
    "                # feature extraction    \n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        for sentence in train_tagged_sents:\n",
    "            X_sentence = []\n",
    "            y_sentence = []\n",
    "            for sent in range(len(sentence)):\n",
    "                X_sentence.append(word_features(sentence, sent))\n",
    "                y_sentence.append(sentence[sent][1])\n",
    "            X_train.append(X_sentence)\n",
    "            y_train.append(y_sentence) \n",
    "\n",
    "            # Train a tagger on the training category\n",
    "            # training using the tuned value\n",
    "            trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "            # Add training data\n",
    "            for x, y in zip(X_train, y_train):\n",
    "                trainer.append(x, y)\n",
    "\n",
    "            # Set trainer parameters\n",
    "            trainer.set_params(paramgrid)\n",
    "\n",
    "            # Train the CRF model\n",
    "            trainer.train('pos.crfsuite')\n",
    "            \n",
    "\n",
    "        for j, test_category in enumerate(categories):\n",
    "            if test_category != train_category:\n",
    "                # Get the tagged sentences for the testing category\n",
    "\n",
    "                test_tagged_sents = sample_sentences(test_category, num_words=5000)\n",
    "\n",
    "                X_test = []\n",
    "                y_test = []\n",
    "                for sentence in test_tagged_sents:\n",
    "                    X_sentence = []\n",
    "                    y_sentence = []\n",
    "                    for sent in range(len(sentence)):\n",
    "                        X_sentence.append(word_features(sentence, sent))\n",
    "                        y_sentence.append(sentence[sent][1])\n",
    "                    X_test.append(X_sentence)\n",
    "                    y_test.append(y_sentence) \n",
    "\n",
    "                \n",
    "                # Testing\n",
    "                # Initialize the tagger\n",
    "                tagger = pycrfsuite.Tagger()\n",
    "                tagger.open('pos.crfsuite')\n",
    "\n",
    "\n",
    "                # predictions\n",
    "                CRF_predictions = [tagger.tag(instance) for instance in X_test]\n",
    "\n",
    "                predicted_tags = [tag for instance_tags in CRF_predictions for tag in instance_tags]\n",
    "                actual_tags = [tag for instance_tags in y_test for tag in instance_tags]\n",
    "\n",
    "                # Compute the F1 score and store it in the matrix\n",
    "                f1 = f1_score(actual_tags, predicted_tags, average='weighted')\n",
    "                f1_matrix[i, j] = f1\n",
    "\n",
    "    return f1_matrix\n",
    "\n",
    "\n",
    "cf_params = {\n",
    "    \"max_iterations\": 50,\n",
    "    \"c1\": 0.01,\n",
    "    \"c2\": 0.001,\n",
    "    \"feature.possible_transitions\": True\n",
    "}\n",
    "\n",
    "# random.seed(1234)\n",
    "# f1_matrix_crf = cross_domain_f1_crf(categories_to_evaluate, paramgrid=cf_params)\n",
    "# np.savetxt(\"insert file path here\", f1_matrix_crf, delimiter=',', fmt='%f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
